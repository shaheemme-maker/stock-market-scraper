name: 5-Minute Stock Scraper

# Grant permission to write changes back to the repo
permissions:
  contents: write

on:
  # External trigger from cron-job.org
  repository_dispatch:
    types: [trigger-scraper]

  # Manual button for testing
  workflow_dispatch:

jobs:
  scrape-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scraper.py

      # --- UPDATED STEP: Commit ALL new files (Shards) ---
      - name: Commit and Push Data
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          
          # 1. Create .nojekyll if missing (Ensures files starting with _ or . work)
          touch .nojekyll
          
          # 2. Add ALL files (This catches history_A.json, history_B.json, etc.)
          git add .
          
          # 3. Commit changes
          # The 'git diff' check prevents the workflow from failing if data hasn't changed
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "ðŸ“ˆ Update stock data [skip ci]"
            git push
          fi
